# -*- coding: utf-8 -*-
"""breast_cancer_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x80Xb5a3TKDKR1VSXg9DA0MmBKP739Ip

## Breast Cancer Prediction Using Python
"""

# Importing Libraries
import numpy
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# Reading data from the file
from google.colab import files
uploaded = files.upload()
df = pd.read_csv('data.csv')
df.head()

df.head()

df.info()

# return all the columns with null values count
df.isna().sum()

# return the size of dataset
df.shape

# remove the column
df=df.dropna(axis=1)

# shape of dataset after removing the null column
df.shape

# describe the dataset
df.describe()

# Get the count of malignant<M> and Benign<B> cells
df['diagnosis'].value_counts()

sns.countplot(df['diagnosis'],label="count")

# label encoding(convert the value of M and B into 1 and 0)
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)

df.head()

sns.pairplot(df.iloc[:,1:5],hue="diagnosis")

# get the correlation
df.iloc[:,1:32].corr()

# visualize the correlation
plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:10].corr(),annot=True,fmt=".0%")

# Split the dataset into Independent(X) and Dependent(Y) datasets
X=df.iloc[:,2:31].values
Y=df.iloc[:,1].values

# Spliting the data into training and test dataset
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20,random_state=0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
X_train=StandardScaler().fit_transform(X_train)
X_test=StandardScaler().fit_transform(X_test)

# Models / Algorithms

def models(X_train,Y_train):
        #logistic regression
        from sklearn.linear_model import LogisticRegression
        log=LogisticRegression(random_state=0)
        log.fit(X_train,Y_train)
        
        
        #Decision Tree
        from sklearn.tree import DecisionTreeClassifier
        tree=DecisionTreeClassifier(random_state=0,criterion="entropy")
        tree.fit(X_train,Y_train)
        
        #Random Forest
        from sklearn.ensemble import RandomForestClassifier
        forest=RandomForestClassifier(random_state=0,criterion="entropy",n_estimators=10)
        forest.fit(X_train,Y_train)
        
        print('[0]logistic regression accuracy:',log.score(X_train,Y_train))
        print('[1]Decision tree accuracy:',tree.score(X_train,Y_train))
        print('[2]Random forest accuracy:',forest.score(X_train,Y_train))
        
        return log,tree,forest

model=models(X_train,Y_train)

# testing the models/result

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

for i in range(len(model)):
    print("Model",i)
    print(classification_report(Y_test,model[i].predict(X_test)))
    print('Accuracy : ',accuracy_score(Y_test,model[i].predict(X_test)))

# prediction of random-forest
pred=model[2].predict(X_test)
print('Predicted values:')
print(pred)
print('Actual values:')
print(Y_test)

from joblib import dump
dump(model[2],"Cancer_prediction.joblib")

"""# Train - Test ratio = 70:30"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.30,random_state=0)

# Feature Scaling

X_train=StandardScaler().fit_transform(X_train)
X_test=StandardScaler().fit_transform(X_test)

# Models / Algorithms

def models(X_train,Y_train):
        #logistic regression
        from sklearn.linear_model import LogisticRegression
        log=LogisticRegression(random_state=0)
        log.fit(X_train,Y_train)
        
        
        #Decision Tree
        from sklearn.tree import DecisionTreeClassifier
        tree=DecisionTreeClassifier(random_state=0,criterion="entropy")
        tree.fit(X_train,Y_train)
        
        #Random Forest
        from sklearn.ensemble import RandomForestClassifier
        forest=RandomForestClassifier(random_state=0,criterion="entropy",n_estimators=10)
        forest.fit(X_train,Y_train)
        
        print('[0]logistic regression accuracy:',log.score(X_train,Y_train))
        print('[1]Decision tree accuracy:',tree.score(X_train,Y_train))
        print('[2]Random forest accuracy:',forest.score(X_train,Y_train))
        
        return log,tree,forest

model=models(X_train,Y_train)

# testing the models/result

for i in range(len(model)):
    print("Model",i)
    print(classification_report(Y_test,model[i].predict(X_test)))
    print('Accuracy : ',accuracy_score(Y_test,model[i].predict(X_test)))

from sklearn.svm import SVC
svc_model = SVC()
svc_model.fit(X_train, Y_train)
y_pred_svc = svc_model.predict(X_test)
print(y_pred_svc)
accuracy_score(Y_test, y_pred_svc)

"""# Train - Test ratio = 60:40"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.40,random_state=0)

# Feature Scaling

X_train=StandardScaler().fit_transform(X_train)
X_test=StandardScaler().fit_transform(X_test)

# Models / Algorithms

def models(X_train,Y_train):
        #logistic regression
        from sklearn.linear_model import LogisticRegression
        log=LogisticRegression(random_state=0)
        log.fit(X_train,Y_train)
        
        
        #Decision Tree
        from sklearn.tree import DecisionTreeClassifier
        tree=DecisionTreeClassifier(random_state=0,criterion="entropy")
        tree.fit(X_train,Y_train)
        
        #Random Forest
        from sklearn.ensemble import RandomForestClassifier
        forest=RandomForestClassifier(random_state=0,criterion="entropy",n_estimators=10)
        forest.fit(X_train,Y_train)
        
        print('[0]logistic regression accuracy:',log.score(X_train,Y_train))
        print('[1]Decision tree accuracy:',tree.score(X_train,Y_train))
        print('[2]Random forest accuracy:',forest.score(X_train,Y_train))
        
        return log,tree,forest

model=models(X_train,Y_train)

# testing the models/result

for i in range(len(model)):
    print("Model",i)
    print(classification_report(Y_test,model[i].predict(X_test)))
    print('Accuracy : ',accuracy_score(Y_test,model[i].predict(X_test)))

from sklearn.svm import SVC
svc_model = SVC()
svc_model.fit(X_train, Y_train)
y_pred_svc = svc_model.predict(X_test)
print(y_pred_svc)
accuracy_score(Y_test, y_pred_svc)



"""# k - Nearest Neighbour Classifier (KNN)"""

#KNN Model
from sklearn.neighbors import KNeighborsClassifier
knn_model = KNeighborsClassifier(n_neighbors=6)
# Train the model using the training sets
knn_model.fit(X_train,Y_train)
y_pred_knn = knn_model.predict(X_test)
print(y_pred_knn)
accuracy_score(Y_test, y_pred_knn)

"""# Support Vector Machine (SVM) Classifier"""

from sklearn.svm import SVC
svc_model = SVC()
svc_model.fit(X_train, Y_train)
y_pred_svc = svc_model.predict(X_test)
print(y_pred_svc)
accuracy_score(Y_test, y_pred_svc)